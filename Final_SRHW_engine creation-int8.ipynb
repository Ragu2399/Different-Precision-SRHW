{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db12cec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 19:01:19.422032: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import common\n",
    "import SRHW_model\n",
    "import torch\n",
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "import tensorrt as trt\n",
    "from matplotlib import pyplot as plt \n",
    "import h5py\n",
    "from torchsummary import summary\n",
    "from NumPyNet.layers.shuffler_layer import Shuffler_layer\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d86a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRHW(\n",
      "  (Conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (DWConv1): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), groups=32, bias=False)\n",
      "  (PWConv1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (DWConv2): Conv2d(16, 16, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), groups=16, bias=False)\n",
      "  (PWConv2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (DWConv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "  (PWConv3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (DWConv4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (PWConv4): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (PS): PixelShuffle(upscale_factor=2)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SRHW_model.Model()\n",
    "#mnist_model.learn()\n",
    "weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b31eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "class ModelData(object):\n",
    "    INPUT_NAME = \"Conv1\"\n",
    "    INPUT_SHAPE = (1, 400, 400)\n",
    "    OUTPUT_NAME = \"prob\"\n",
    "#     OUTPUT_SIZE = 10\n",
    "    DTYPE = trt.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3a8ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def populate_network(network, weights):\n",
    "    # Configure the network layers based on the weights provided.\n",
    "    \n",
    "\n",
    "    #line1\n",
    "    \n",
    "    input_tensor = network.add_input(name=ModelData.INPUT_NAME, dtype=ModelData.DTYPE, shape=ModelData.INPUT_SHAPE)\n",
    "\n",
    "    conv1_w = weights['Conv1.weight'].numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    conv1 = network.add_convolution_nd(input=input_tensor, num_output_maps=32, kernel_shape=(3,3), kernel=conv1_w)\n",
    "    \n",
    "    \n",
    "    conv1.stride_nd = (1, 1)\n",
    "    conv1.padding_nd = (1,1)\n",
    "    \n",
    "#     quant1=network.add_quantize(input_tensor,1.0)\n",
    "    \n",
    "   \n",
    "    #\n",
    "    scale1=network.add_scale(input=conv1.get_output(0),\n",
    "                             mode=trt.ScaleMode.UNIFORM)\n",
    "    \n",
    "    \n",
    "    #\n",
    "    \n",
    "    \n",
    "    #line2\n",
    "\n",
    "    relu1 = network.add_activation(input=scale1.get_output(0), type=trt.ActivationType.RELU)\n",
    "\n",
    "   \n",
    "    #\n",
    "    \n",
    "    #line3\n",
    "    \n",
    "    conv2_w = weights['DWConv1.weight'].numpy()\n",
    "   \n",
    "    conv2 = network.add_convolution_nd(input=relu1.get_output(0), num_output_maps=32, kernel_shape=(1,5), kernel=conv2_w)\n",
    "    conv2.stride_nd = (1, 1)\n",
    "    conv2.padding_nd=(0,2)\n",
    "    conv2.num_groups=32\n",
    "    \n",
    "  \n",
    "    #\n",
    "    \n",
    "    \n",
    "    scale2=network.add_scale(input=conv2.get_output(0),\n",
    "                             mode=trt.ScaleMode.UNIFORM)\n",
    "    \n",
    "    \n",
    " \n",
    "    #\n",
    "    \n",
    "    \n",
    "    \n",
    "    conv3_w = weights['PWConv1.weight'].numpy()\n",
    "   \n",
    "    conv3 = network.add_convolution_nd(input=scale2.get_output(0), num_output_maps=16, kernel_shape=(1,1), kernel=conv3_w)\n",
    "    conv3.stride_nd = (1, 1)\n",
    "\n",
    "    \n",
    "    scale3=network.add_scale(input=conv3.get_output(0),\n",
    "                             mode=trt.ScaleMode.UNIFORM)\n",
    "    \n",
    "    \n",
    "    relu2 = network.add_activation(input=scale3.get_output(0), type=trt.ActivationType.RELU) #1\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #line4\n",
    "    \n",
    "    \n",
    "    \n",
    "    conv4_w = weights['DWConv2.weight'].numpy()\n",
    "    \n",
    "    conv4 = network.add_convolution_nd(input=relu2.get_output(0), num_output_maps=16, kernel_shape=(1,5), kernel=conv4_w)\n",
    "    conv4.stride_nd = (1, 1)\n",
    "    conv4.padding_nd = (0,2)                                                                            #4\n",
    "    conv4.num_groups=16\n",
    "    \n",
    "    scale4=network.add_scale(input=conv4.get_output(0),\n",
    "                             mode=trt.ScaleMode.UNIFORM)\n",
    "                         \n",
    "    \n",
    "    \n",
    "\n",
    "    conv5_w = weights['PWConv2.weight'].numpy()\n",
    "    \n",
    "    conv5 = network.add_convolution_nd(input=scale4.get_output(0), num_output_maps=32, kernel_shape=(1,1), kernel=conv5_w)\n",
    "    conv5.stride_nd = (1, 1)\n",
    "                                                                          \n",
    "    scale5=network.add_scale(input=conv5.get_output(0),\n",
    "                             mode=trt.ScaleMode.UNIFORM)\n",
    "\n",
    "    \n",
    "    #line5\n",
    "    \n",
    "    add1=network.add_elementwise(conv1.get_output(0),scale5.get_output(0),trt.ElementWiseOperation.SUM)\n",
    "    \n",
    "    \n",
    "    #line 6\n",
    "    \n",
    "    relu6 = network.add_activation(input=add1.get_output(0), type=trt.ActivationType.RELU)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #line7\n",
    "\n",
    "    conv6_w = weights['DWConv3.weight'].numpy()\n",
    "\n",
    "    conv6 = network.add_convolution_nd(input=relu6.get_output(0), num_output_maps=32, kernel_shape=(3,3), kernel=conv6_w)\n",
    "    conv6.stride_nd = (1, 1)\n",
    "    conv6.padding_nd = (1, 1)                                                                            #8\n",
    "    conv6.num_groups=32\n",
    "    \n",
    "    \n",
    "    \n",
    "    scale6=network.add_scale(input=conv6.get_output(0),\n",
    "                             mode=trt.ScaleMode.UNIFORM)\n",
    "    \n",
    "    \n",
    "    conv7_w = weights['PWConv3.weight'].numpy()\n",
    "    \n",
    "    conv7 = network.add_convolution_nd(input=scale6.get_output(0), num_output_maps=16, kernel_shape=(1,1), kernel=conv7_w)\n",
    "    conv7.stride_nd = (1, 1)\n",
    "    \n",
    "        \n",
    "    scale7=network.add_scale(input=conv7.get_output(0),\n",
    "                             mode=trt.ScaleMode.UNIFORM)\n",
    "    \n",
    "    \n",
    "    relu7 = network.add_activation(input=scale7.get_output(0), type=trt.ActivationType.RELU)  #9\n",
    "    \n",
    "#                                                                              #10\n",
    "                                            \n",
    "    \n",
    "    \n",
    "\n",
    "    #line 8\n",
    "\n",
    "    \n",
    "    conv8_w = weights['DWConv4.weight'].numpy()\n",
    " \n",
    "    \n",
    "    conv8 = network.add_convolution_nd(input=relu7.get_output(0), num_output_maps=16, kernel_shape=(3,3), kernel=conv8_w)\n",
    "    conv8.stride_nd = (1,1)\n",
    "    conv8.padding_nd = (1,1)\n",
    "    conv8.num_groups=16\n",
    "    \n",
    "    \n",
    "    scale8=network.add_scale(input=conv8.get_output(0),\n",
    "                             mode=trt.ScaleMode.UNIFORM)\n",
    "    \n",
    "    \n",
    "    \n",
    "    conv9_w = weights['PWConv4.weight'].numpy()\n",
    " \n",
    "    \n",
    "    conv9 = network.add_convolution_nd(input=scale8.get_output(0), num_output_maps=4, kernel_shape=(1,1), kernel=conv9_w)\n",
    "    conv9.stride_nd = (1,1)\n",
    "\n",
    "    scale9=network.add_scale(input=conv9.get_output(0),\n",
    "                             mode=trt.ScaleMode.UNIFORM)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "#     print(scale9.get_output(0).shape,\"scale9 shape\")\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###########################################################\n",
    "    \n",
    "    #########################################################\n",
    "    \n",
    "    \n",
    "                        ##PIXEL SHUFFLE##\n",
    "    \n",
    "    \n",
    "    ############################################################\\\\\n",
    "    \n",
    "    ###########################################################\n",
    "\n",
    "    reshape = network.add_shuffle(input=scale9.get_output(0))\n",
    "    \n",
    "    #[num, new_ch, scale_factor, scale_factor, height, width])\n",
    "    \n",
    "    reshape.reshape_dims=[1,1,2,2,400,400]\n",
    "\n",
    "#     reshape.reshape_dims=[4,1,2,2,7000,700]\n",
    "\n",
    "    reshape1=network.add_shuffle(input=reshape.get_output(0))\n",
    "    \n",
    "    \n",
    "    reshape1.first_transpose = trt.Permutation([0, 1, 4, 2, 5, 3])\n",
    "    \n",
    "    \n",
    "    reshape2=network.add_shuffle(input=reshape1.get_output(0))\n",
    "    \n",
    "                        #[num, new_ch, new_height, new_width]\n",
    "    reshape2.reshape_dims = [800,800]\n",
    "    \n",
    "    \n",
    "#     print(reshape2.get_output(0).shape,\"reshape2.get_output(0).shape\")\n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "#     reshape2.get_output(0).name = ModelData.OUTPUT_NAME\n",
    "    network.mark_output(tensor=reshape2.get_output(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b92683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_int8_engine(weights,batch_size=32):\n",
    "#     with trt.Builder(TRT_LOGGER) as builder, builder.create_network() as network, builder.create_builder_config() as config, trt.CaffeParser() as parser, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        # We set the builder batch size to be the same as the calibrator's, as we use the same batches\n",
    "        # during inference. Note that this is not required in general, and inference batch size is\n",
    "        # independent of calibration batch size.\n",
    "    builder = trt.Builder(TRT_LOGGER)\n",
    "    network = builder.create_network()\n",
    "    config = builder.create_builder_config()\n",
    "    runtime = trt.Runtime(TRT_LOGGER)\n",
    "#     builder.max_batch_size = batch_size\n",
    "    config.max_workspace_size = common.GiB(1)\n",
    "    \n",
    "    config.set_flag(trt.BuilderFlag.INT8)\n",
    "\n",
    "    populate_network(network, weights)\n",
    "    plan = builder.build_serialized_network(network, config)\n",
    "    return runtime.deserialize_cuda_engine(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c1376ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loads a random test case from pytorch's DataLoader\n",
    "def load_random_test_case(model, pagelocked_buffer):\n",
    "    # Select an image at random to be the test case.\n",
    "    img, expected_output = model.get_random_testcase()\n",
    "    # Copy to the pagelocked input buffer\n",
    "    np.copyto(pagelocked_buffer, img)\n",
    "    return expected_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3034a006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRHW(\n",
      "  (Conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (DWConv1): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), groups=32, bias=False)\n",
      "  (PWConv1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (DWConv2): Conv2d(16, 16, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), groups=16, bias=False)\n",
      "  (PWConv2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (DWConv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "  (PWConv3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (DWConv4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (PWConv4): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (PS): PixelShuffle(upscale_factor=2)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TensorRT] WARNING: Calibrator is not being used. Users must provide dynamic range for all tensors that are not Int32.\n",
      "[TensorRT] ERROR: 4: [standardEngineBuilder.cpp::initCalibrationParams::2050] Error Code 4: Internal Error (Calibration failure occurred with no scaling factors detected. This could be due to no int8 calibrator or insufficient custom scales for network layers. Please see int8 sample to setup calibration correctly.)\n",
      "[TensorRT] ERROR: 2: [builder.cpp::buildSerializedNetwork::417] Error Code 2: Internal Error (Assertion enginePtr != nullptr failed.)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "deserialize_cuda_engine(): incompatible function arguments. The following argument types are supported:\n    1. (self: tensorrt.tensorrt.Runtime, serialized_engine: buffer) -> tensorrt.tensorrt.ICudaEngine\n\nInvoked with: <tensorrt.tensorrt.Runtime object at 0x7efad0d385f0>, None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4381/59534975.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0moutput_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexecution_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv_bicubic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu_bicubic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ms :Float 32,per frame execution_time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4381/59534975.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Do inference with TensorRT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     engine = build_engine(weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_int8_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Build an engine, allocate buffers and create a stream.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4381/3277444362.py\u001b[0m in \u001b[0;36mbuild_int8_engine\u001b[0;34m(weights, batch_size)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpopulate_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mplan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_serialized_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize_cuda_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: deserialize_cuda_engine(): incompatible function arguments. The following argument types are supported:\n    1. (self: tensorrt.tensorrt.Runtime, serialized_engine: buffer) -> tensorrt.tensorrt.ICudaEngine\n\nInvoked with: <tensorrt.tensorrt.Runtime object at 0x7efad0d385f0>, None"
     ]
    }
   ],
   "source": [
    "def main(image):\n",
    "    common.add_help(description=\"Runs an MNIST network using a PyTorch model\")\n",
    "    # Train the PyTorch model\n",
    "    \n",
    "    model = SRHW_model.Model()\n",
    "    #mnist_model.learn()\n",
    "    weights = model.get_weights()\n",
    "    # Do inference with TensorRT.\n",
    "#     engine = build_engine(weights)\n",
    "    engine = build_int8_engine(weights)\n",
    "    \n",
    "    # Build an engine, allocate buffers and create a stream.\n",
    "    # For more information on buffer allocation, refer to the introductory samples.\n",
    "    inputs, outputs, bindings, stream = common.allocate_buffers(engine)\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    imlryuv=image.convert('YCbCr')\n",
    "    y,u,v=imlryuv.split()\n",
    "    y=np.array(y).astype(np.float32)\n",
    "    y=y/255\n",
    "    input_image=y\n",
    "\n",
    "    u=np.array(u)\n",
    "    v=np.array(v)\n",
    "    u_bicubic=cv2.resize(u,(800,800),interpolation = cv2.INTER_CUBIC)\n",
    "    # plt.imshow(u_bicubic)\n",
    "    v_bicubic=cv2.resize(v,(800,800),interpolation = cv2.INTER_CUBIC)\n",
    "    #converting RGB into YCRCB ad RUNNIG infernece with External \n",
    "    \n",
    "    \n",
    "   \n",
    "    time_value=[]\n",
    "#     print(start_time,\"start_time\")\n",
    "    \n",
    "#     print(input_image.shape,\"input_image.shape\")\n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    for i in range(1000):\n",
    "\n",
    "        pagelocked_buffer=inputs[0].host\n",
    "        np.copyto(pagelocked_buffer, input_image.ravel())\n",
    "\n",
    "        # For more information on performing inference, refer to the introductory samples.\n",
    "        # The common.do_inference function will return a list of outputs - we only have one in this case.\n",
    "        [output] = common.do_inference(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n",
    "\n",
    "        \n",
    "        \n",
    "    end_time = datetime.datetime.now()\n",
    "\n",
    "    time_diff = end_time - start_time\n",
    "\n",
    "    execution_time = time_diff.total_seconds() * 1000\n",
    "    execution_time=execution_time/1000\n",
    "#     time_value.append(execution_time)\n",
    "    \n",
    "\n",
    "    print(output.dtype)\n",
    "    \n",
    "    return output,execution_time,input_image,v_bicubic,u_bicubic\n",
    "if __name__ == '__main__':\n",
    "    image=Image.open(\"/home/raguhtic/Downloads/eye1_400.jpg\")\n",
    "    newsize = (400, 400)\n",
    "    image = image.resize(newsize)\n",
    "\n",
    "    output_image,execution_time,input_image,v_bicubic,u_bicubic=main(image)\n",
    "    print(execution_time,\"ms :Float 32,per frame execution_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2222cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_image=np.array(output_image)\n",
    "image=Image.open(\"/home/raguhtic/Downloads/eye1_1000.jpg\")\n",
    "newsize = (800, 800)\n",
    "image = image.resize(newsize)\n",
    "imlryuv=image.convert('YCbCr')\n",
    "y,u,v=imlryuv.split()\n",
    "y=np.array(y).astype(np.float32)\n",
    "y=y/255\n",
    "\n",
    "# plt.figure(figsize=(5,5))\n",
    "# plt.imshow(y)\n",
    "output_image=np.reshape(output_image,(800,800))\n",
    "plt.figure(figsize=(25,25))\n",
    "plt.subplot(131)\n",
    "plt.title('Input Image')\n",
    "plt.imshow(input_image)\n",
    "plt.subplot(132)\n",
    "plt.title('output Image')\n",
    "plt.imshow(output_image)\n",
    "plt.subplot(133)\n",
    "plt.title('Y')\n",
    "plt.imshow(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973e438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10, sqrt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "  \n",
    "\n",
    "\n",
    "def psnr(SR,HR):\n",
    "  diff=np.subtract(HR,SR)\n",
    "  mse=np.mean(np.power(diff,2))\n",
    "  return -10*math.log10(mse)\n",
    "def main():\n",
    "#      original = cv2.imread(\"original_image.png\")\n",
    "#      compressed = cv2.imread(\"compressed_image.png\", 1)\n",
    "     value = psnr(y, output_image)\n",
    "     print(f\"PSNR value is {value} dB\")\n",
    "       \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "ssim=ssim(output_image,y)\n",
    "print(\"SSIM(Structural Simularity) :\",ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95897c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
